1.  | **联邦学习的资料有哪些？**
    | 在https://github.com/FederatedAI/FATE/tree/master/doc
      下可以找到相关资料，另外FATE官网https://www.fedai.org/
      也有相关介绍

2.  | **联邦学习和分布式机器学习的本质区别是什么，有什么技术上的难点？**
    | 联邦学习更侧重各方本地计算，数据的隐私保护。技术难点上，计算和通信代价，如何保护隐私都有很多挑战。

3.  | **联邦学习与边缘计算都关注在不同节点上学习，它们的侧重点有什么不同？**
    | 联邦学习更侧重于数据隐私保护，边缘计算更侧重于将计算机工作负载移近边缘端可以减少集中式数据中心的延迟，带宽和开销

4.  | **联邦学习是怎么解决节点间通信问题的？**
    | 联邦学习跨站点通信，不同框架可能都采取的是不同方案，目前FATE开源系统通信这块是基于grpc协议。

5.  | **差分隐私技术在联邦学习中应用的局限性和挑战是什么？**
    | 差分隐私优点在于保证数据信息安全，通过在参与方各自的原始数据上不断加噪音来减弱任意一方数据对于整体数据的影响，缺点在于牺牲训练效果，过多的噪音会降低模型训练的效果，因此参与方们使用差分隐私时需要在数据安全和准确度上做取舍。研究表明，在联邦学习中，如果参与方数量较少，用差分隐私来进行数据的隐私保护，模型的准确率会较低

6.  | **联邦学习与 Reza Shokri 发表于CCS’15《Privacy-Preserving Deep
      Learning》一文相比，主要区别和优势在哪里？**
    | Reza Shokri 发表于CCS’15《Privacy-Preserving Deep
      Learning》比较偏向横向联邦场景，而联邦学习定义比较广，包括横向联邦，纵向联邦，联邦迁移学习，并且不局限于具体一个算法，包括传统机器学习，也包括深度学习，迁移学习等。

7.  | **联邦学习学术界情况**
    | 近一两年来，关于联邦学习的研究与应用发展迅速。联邦学习与隐私和安全协议的结合。比如联邦学习与差分隐私，同态加密，和多方安全计算以对用户数据隐私和模型安全进行保护。其中联邦学习与差分隐私的结合较多。
      联邦学习和模型压缩，传输效率等的结合，以解决（在加密条件下）联邦学习训练效率低的问题。
      联邦学习的算法方向：除了经典的算法，比如逻辑回归，决策树等机器学习算法在联邦学习中的应用，深度神经网络也大量应用于联邦学习中。Google
      还提出了split learning 对基于深度神经网络的联邦学习的拓展。
      能够对抗恶意攻击的联邦学习算法也是一个比较热的联邦学习研究领域。
      联邦学习在工业界中的应用：联邦学习在安防，金融，零售中已有应用落地。联邦学习在医疗领域的应用是一个比较热的研究领域。联邦学习在其他更多领域也在拓展中。

8.  **联邦学习发展趋势**

    -  现在联邦学习大部分是集中在横向联邦学习场景（这是google最先提出应用于手机端的toC模式）。联邦学习将向纵向联邦学习（和更实际的）场景中拓展（这是有WeBank提出和引领的，主要是toB模式）。
    -  联邦学习与移动互联网，物联网（包括车联网）和5G将有深度的结合以拓展联邦学习的应用场景和学习效率。
    -  联邦学习将和迁移学习，半监督，非监督等学习算法结合以解决在弱监督，小数据的应用场景。者是实现普惠AI的必经之路。
    -  更多更广的隐私安全协议和算法将与联邦学习结合以更好地解决用户隐私保护和模型安全保护问题。将有更多的，更成熟的联邦学习框架问世。现在已经有FATE
       (WeBank), tensorflow-Federated (google), PySyft
       (OpenMind)等开源联邦学习框架。
    -  联邦学习涉及多个相互独立的参与方，如何公平地分配利益和有效地吸引更多参与者，需要建立一个联邦学习生态。微众银行正在引领这个方向。

9.  **联邦学习不足之处**

    -  在保护用户隐私和安全的条件下，联邦学习的训练效率是联邦学习应用落地的一个瓶颈。更高效、更坚固的基于用户隐私和安全的联邦学习方法需要被提出。
    -  目前市面上成熟的企业级联邦学习框架可以说还是空白。微众银行的FATE框架正在向这个方向努力发展。除了微众银行之外，现在学术界和工业界主要是以Google提出的横向联邦学习为基础进行研究和应用。但横向联邦学习有其局限性，其并不能完全适用于在不同领域企业之间的业务合作上。
       因此需要对纵向联邦学习和联邦迁移学习的场景进行更深入的研究。
    -  联邦学习虽然有天然保护用户隐私的功能（e.g., 通过secure
       aggregation），但仍然有泄露用户数据隐私的风险，特别在联邦学习参与者的恶意攻击下。因此需要能对抗恶意攻击的更坚固的联邦学习算法。
    -  联邦学习（包括整个AI领域），现在还不存在一个像软件工程领域的系统且成熟的工程开发方法论。因此在联邦学习的应用落地上没有很多经验可以借鉴。这是一个联邦学习应用落地风险点。

10. | **FATE是否可以支持深度学习的模型？**
    | 可以支持，FATE
      1.1版本已经支持横向深度学习(DNN)模型，此外，预计在FATE
      1.2版本会发布纵向深度学习模型

11. | **FATE框架现阶段能支持多少个client一起联邦？可以实际部署到手机端这种计算能力弱的device上面吗？**
    | 这个和机器资源，模型大小都有关系，理论上来说，FATE对client个数没有限制。目前的版本，FATE还不支持手机端这样的设备。

12. | **目前FATE里面支持多少种模型聚合模式?**
    | 目前横向联邦支持明文的加权平均，以及加密状态下的secureaggregation

13. | **如果想在实际场景中部署一个联邦学习的系统，每个client的模型从哪里来？是需要在client本地运行一个程序以获取模型还是通过什么其他方式？如果每个client的feature不一致（纵向联邦学习），那么每个client本地的模型结构就不同，这种情况下需要对不同的client单独设计模型吗？**
    | 横向联邦中，可以不必然要求本地先有个模型，横向联邦中算法运行过程中可以生成模型，当然，横向联邦也可以支持预加载本地训练好的模型。纵向联邦中，目前不支持预加载模型，模型是双方或者多方共建的，不同的纵向联邦算法他的模型结构都不同。

14. | **横向联邦是不是一个中心化的模型？**
    | 常见的横向联邦通常需要一个服务器端来进行模型聚合，但这与我们通常理解的中心化训练是不同的，传统的中心化训练,数据集中在同一个数据中心，
      训练是在内部计算集群中，
      通信瓶颈不明显。而横向联邦学习是一种模型聚合的计算范式，不需要数据的移动，但会涉及跨站点，跨设备的通信，通信的挑战比较大。

15. | **横向联邦的模型聚合方式，除了平均和加权平均之外，还主要有哪些方法？**
    | 和很多分布式学习算法一样，模型聚合也是一个在不断研究的问题，除了常用的平均和加权平均之外，还有像one
      shot、few
      shot等方式，此外，过去常用的分布式机器学习中的模型聚合方案也可以作为重要的参考。

16. | **数据非独立同分布问题，每一个参与方如果收集的数据差异很大，如何保证模型效果质量？**
    | 这是实际应用中常见的一个问题，从工程的角度，我们可以保留一份公用的全局数据集，通过这个公用的数据集来尽量消除各个客户端之间的差异。现在已经有很多论文提出针对Non-IID数据的分布式优化算法，例如，FedProx，可以参考最新的关于Federated
      Optimization的论文。也可以利用迁移学习，来降低各参与方数据的差异性。

17. | **BN层如何做聚合？**
    | 一种常见的思路是每一方(或者设备)需要先向server发送各自均值，server聚合均值后广播给各方，各方根据聚合均值算各自方差，发给server聚合方差，server把聚合后的方差广播给各方。这样每一方就可以根据总体均值和总体方差做bn。

18. | **数据在纵向联邦的ID不能出域的情况下(加密也不能出)，如何把多方的ID对齐？**
    | 我们已经实现了ID对齐方法，请参考FATE最新版本：https://github.com/FederatedAI/FATE/blob/master/federatedml/statistic/intersect/README.md

19. | **数据是否出去方面，联邦学习如何自证清白？**
    | 一方面我们的联邦学习设计是严格遵守当前的法律法规，也就是数据不出域这个前提来进行；另一方面我们也在建立相关的联邦学习标准，以标准的方式来作为数据安全的评判标准。

20. **我们目前是不是只用到同态加密来保证数据安全？其它数据隐私安全的方法，比如安全多方、差分隐私这些有没有尝试？**
    我们目前也在尝试多方安全计算（比如ABY和SPDZ）、差分隐私等保护数据隐私安全的方法.

21. | **模型的可解释性方面做了一些什么样的努力？**
    | 模型的解释性上，尤其是深度学习模型的解释性，在学术界都是一个很大的挑战。
      目前FATE在深度学习模型的模型解释性上涉及的还不多，在LR，SecureBoost树模型上有些工作，比如可视化。

22. | **激励机制和贡献度问题，如何吸引更多的参与方参与？**
    | 从实际落地的角度，数据源方进入联邦数据网络里面，如果他的数据被更多应用方使用，
      他会获得更多经济收益，相反，如果他的数据没有给应用方带来价值，他将慢慢会被淘汰。在联邦数据网络里面动态的实现优胜劣汰，
      数据源为了获取商业价值，会不断丰富和提高自身数据的质量，
      应用方会因为这个网络中有对他有价值的多样化的数据源而不断加入；从研究的角度，这个问题涉及到博弈论等方面的知识，我们当前也在这方面做更多的研究工作。
